# Dag Controller

Dag Controller 是一款任务编排调度工具，可以编排调度有向无环图（DAG）类型的作业，该作业由多个任务组成，且任务之间存在先后关系，组成一个有向无环图（DAG）。

Dag Controller 可以结合 NebulaGraph Analytics 进行复杂的图计算。例如 Dag Controller 将算法调用请求发送给 NebulaGraph Analytics ，NebulaGraph Analytics 保存结果至 NebulaGraph 或 HDFS，Dag Controller 再将上次的计算结果作为下一个算法任务的输入创建新的任务。

本文介绍如何使用 Dag Controller。

!!! enterpriseonly

    如需获取 Dag Controller 安装包，请发送邮件至 inquiry@vesoft.com。

## 版本兼容性

Dag Controller、Nebula Analytics 版本和 NebulaGraph 内核的版本对应关系如下。

|Dag Controller 版本|Nebula Analytics 版本|NebulaGraph 版本|
|:---|:---|---|
|{{dag.release}}、3.2.0|{{plato.release}}|{{nebula.release}}|

## 前提条件

- 已部署 2.2.x 或以上版本的 [HDFS](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html)。

- 已安装 1.8 版本的 JDK。

## 准备工作

不同的环境安装包和命令略有区别，本文的准备工作如下：

- 操作系统为 CentOS 7。
- 如果 NebulaGraph Analytics 和 Dag Controller 分别部署在多台机器，请确保机器网络互通。
- 如果 NebulaGraph Analytics 是分布式架构，请确保路径、端口等配置相同。

## 注意事项

- BFS、SSSP 算法需要对参数`root`做校验，只支持一个上游组件，且必须要指定行和列。存在多个文件时，随机取一个，找不到行、列或者文件时直接报错。

- 相似度算法，不限制上游组件的格式，但是需要指定列。存在多个文件时，随机叠加然后取前 N 条数据进行处理，指定了行和列、或者指定列不存在的话直接报错。

## 部署 NebulaGraph Analytics

1. 安装 libatomic、psmisc。

  ```
  $ sudo yum -y install libatomic psmisc
  ```

2. 安装 NebulaGraph Analytics。

  ```
  $ sudo rpm -ivh <analytics_package_name> --prefix <install_path>
  $ sudo chown <user>:<user> -R <install path>
  ```

  例如：

  ```
  $ sudo rpm -ivh nebula-analytics-{{plato.release}}-centos.x86_64.rpm --prefix=/home/vesoft/nebula-analytics
  $ sudo chown vesoft:vesoft -R /home/vesoft/nebula-analytics
  ```

3. 配置`set_env.sh`文件，路径为`nebula-analytics/scripts/set_env.sh`。配置正确的 Hadoop 路径和 JDK 路径。如果有多台机器，请确保路径一致。

  ```
  export HADOOP_HOME=<hadoop_path>
  export JAVA_HOME=<java_path>
  ```

## 部署 Dag Controller

1. 配置 Dag Controller 机器 SSH 免密登录 NebulaGraph Analytics 机器，以及 NebulaGraph Analytics 集群内所有节点间的 SSH 相互免密登录。

  例如机器 A（Dag Controller）通过 SSH 免密登录至 NebulaGraph Analytics 集群 B 中的机器 B-1。请在机器 A 上执行如下命令：

  ```
  //执行后按提示生成密钥，默认按回车即可。
  $ ssh-keygen -t rsa

  //将机器 A 的公钥文件安装到机器 B-1 对应的用户下，即可从机器 A 免密登录机器 B-1。
  $ ssh-copy-id -i ~/.ssh/id_rsa.pub <B_user>@<B_IP>
  ```

  按同样方法设置 A 免密登录机器 B-2、B-3 等，以及集群 B 内所有机器的互相免密登录。

2. 添加以下内容至`~/.bash_profile`文件内，执行`source ~/.bash_profile`使其生效。

  ```
  eval $(ssh-agent)
  ssh-add ~/.ssh/id_rsa
  ```

3. 安装 Dag Controller。

  ```
  $ sudo rpm -ivh <dag_package_name> --prefix <install_path>
  $ sudo chown <user>:<user> -R <install path>
  ```

  例如：

  ```
  $ sudo rpm -ivh dag-ctrl-{{dag.release}}-centos.x86_64.rpm --prefix=/home/vesoft/dag-ctrl
  $ sudo chown vesoft:vesoft -R /home/vesoft/dag-ctrl
  ```

4. 配置`dag-ctrl-api.yaml`文件，路径为`dag-ctrl/etc/dag-ctrl-api.yaml`。配置 NebulaGraph Analytics 机器的用户名及端口，如果有多台机器，请确保使用相同用户名。

  ```yaml
  # NebulaGraph Analytics 机器的用户名以及 SSH 端口。
  SSH:
    UserName: vesoft
    Port: 22

  #任务和作业的并行线程池大小。
  JobPool:
    Sleep: 3    # 3 秒检查一次有没有未执行的作业。
    Size: 3    # 同时可以执行 3 个作业。
  TaskPool:
    CheckStatusSleep: 1    # 1 秒检查一次任务状态。
    Size: 10    #同时可以执行 10 个任务。

  Dag:
    VarDataListMaxSize: 100    # 如果读取 HDFS 的列，则限制为每次 100 条数据。
  ```

5. 配置`tasks.yaml`文件，路径为`dag-ctrl/etc/tasks.yaml`。只需配置算法文件的具体路径（`exec_file`参数）。当前所有`exec_file`参数都配置为`run_algo.sh`文件的路径。

  !!! note

      - 算法文件在 NebulaGraph Analytics 安装路径下的`scripts`目录内。
      - 如果有多台机器，请确保算法文件路径一致。
      - 其它参数是算法的执行参数，后续在[可视化工作流页面](../nebula-explorer/workflow/2.create-workflow.md)配置。

  ```bash
  exec_file: /home/xxx/nebula-analytics/scripts/run_algo.sh
  ```

6. 启动 Dag Controller。

  ```
  $ cd <dag_ctrl_install_path>
  $ ./scripts/start.sh
  ```
  
7. 查看 Dag Controller 的端口状态，确认是否启动成功。默认端口为`9002`，在`dag-ctrl-api.yaml`文件内设置。

  ```
  $ netstat -aon | grep 9002
  ```

## 下一步

NebulaGraph Analytics 和 Dag Controller 都配置并启动成功后，在 NebulaGraph Explorer 上进行资源配置后即可进行复杂图计算。详情参见[资源配置](../nebula-explorer/workflow/1.prepare-resources.md)。

## 常见问题

### 如果 Graph 服务返回的查询结果数据量过大，会导致 Dag Controller 服务崩溃吗？

Dag Controller 服务仅仅提供调度功能，不会崩溃，但是数据量过大可能会导致 NebulaGraph Analytics 服务读写 HDFS 或者 NebulaGraph 时内存不足而崩溃。

### 如果一个作业中的某个任务失败，能否从失败的任务开始重新执行？

暂不支持，只能整体重新执行。

### 如果任务结果保存很慢，或任务间数据传输很慢，如何加速？

Dag Controller 包含图查询组件和图计算组件。图查询是发送请求给 Graph 进程进行查询，因此只能增大 Graph 服务的内存进行加速；图计算是由 NebulaGraph Analytics 提供的分布式节点进行计算，可以增大计算集群规模进行加速。

### HDFS 服务器无法连接时，任务状态一直为`running`怎么办？

为 HDFS 连接设置超时时间、次数，配置如下：

```bash
<configuration>
<property>
    <name>ipc.client.connect.timeout</name>
    <value>3000</value>
</property>

<property>
    <name>ipc.client.connect.max.retries.on.timeouts</name>
    <value>3</value>
</property>
</configuration>
```

### 任务运行失败，报错`Err:dial unix: missing address`怎么办？

修改`dag-ctrl/etc/dag-ctrl-api.yaml`配置文件，配置 SSH 的`UserName`。

### 任务运行失败，报错`bash: /home/xxx/nebula-analytics/scripts/run_algo.sh: No such file or directory`怎么办？

修改`dag-ctrl/etc/tasks.yaml`配置文件，配置算法执行路径`exec_file`。

### 任务运行失败，报错`/lib64/libm.so.6: version 'GLIBC_2.29' not found (required by /home/vesoft/jdk-18.0.1/jre/lib/amd64/server/libjvm.so)`怎么办？

由于 JDK18 版本太新，而操作系统版本太旧，`YUM`无法下载`GLIBC_2.29`，可以安装 JDK1.8，请同步修改`nebula-analytics/scripts/set_env.sh`中的 JDK 地址。

### 任务运行失败，报错`handshake failed: ssh: unable to authenticate, attempted methods [none publickey], no supported methods remain`怎么办？

重新配置`.ssh`文件夹及`.ssh/authorized_keys`文件的权限，`.ssh`文件夹权限为`744`，`.ssh/authorized_keys`文件权限为`600`。

### 任务运行失败，报错`There are 0 NebulaGraph Analytics available. clusterSize should be less than or equal to it`怎么办？

可能是因为如下原因：

- 未配置 NebulaGraph Analytics。请按本文档配置 NebulaGraph Analytics。

- 已配置 NebulaGraph Analytics，但是无法与 Dag Controller 联通。例如 地址错误、未配置 SSH、两个服务的启动用户不一致（导致 SSH 登录失败）等。

### 任务运行失败，报错`broadcast.hpp:193] Check failed: (size_t)recv_bytes >= sizeof(chunk_tail_t) recv message too small: 0`怎么办？

任务要处理的数据量过小，但是配置的计算节点数与进程数太多。需要在提交作业时设置较小的`clusterSize`和`processes`。
